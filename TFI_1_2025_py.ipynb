{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoetw7FuPVNhGYSMLLRI86",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krl05oP11/SchallerPonceIA/blob/main/TFI_1_2025_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DCDA TFI 1ra parte - Agosto 2025**\n",
        "\n",
        "Parte 1: Importar las librerías que voy a usar."
      ],
      "metadata": {
        "id": "BTkWKFN8uVqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para el manejo de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Para visalización estática\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Para visualización interactiva\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Para mapas interactivos\n",
        "import folium\n",
        "from folium import plugins\n",
        "\n",
        "# Para Análisis Estadístico\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency, pearsonr\n",
        "\n",
        "# Configuraciones de visualización\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "# No mostrar los warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Aviso de tudo bôm\n",
        "print(\"Librerías importadas OK!\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"Numpy version: {np.__version__}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6M4Y2j-uTMc",
        "outputId": "46e3ec3a-4893-4a50-b55a-b55f486aa881"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Librerías importadas OK!\n",
            "Pandas version: 2.2.2\n",
            "Numpy version: 2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 2: Cargar los datos desde los CSV de Olist"
      ],
      "metadata": {
        "id": "-BMwWTTiyxln"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcN42PRVs3N5",
        "outputId": "596c97e9-1c74-407a-b742-b659a98d9dc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":-0 Cargando datasets...\n",
            "==================================================\n",
            "OK! orders: 99,441 filas, 8 columnas\n",
            "OK! order_items: 112,650 filas, 7 columnas\n",
            "OK! order_payments: 103,886 filas, 5 columnas\n",
            "OK! order_reviews: 99,224 filas, 7 columnas\n",
            "OK! products: 32,951 filas, 9 columnas\n",
            "OK! customers: 99,441 filas, 5 columnas\n",
            "OK! geolocation: 1,000,163 filas, 5 columnas\n",
            "OK! sellers: 3,095 filas, 4 columnas\n",
            "OK! product_category: 71 filas, 2 columnas\n",
            "==================================================\n",
            ";-) Total de datasets cargados: 9\n"
          ]
        }
      ],
      "source": [
        "data_path = \"/content/\"  # Archivos en el directorio de Colab\n",
        "\n",
        "# Diccionario para simplificar los nombres de archivos\n",
        "archivos = {\n",
        "    'orders': 'olist_orders_dataset.csv',\n",
        "    'order_items': 'olist_order_items_dataset.csv',\n",
        "    'order_payments': 'olist_order_payments_dataset.csv',\n",
        "    'order_reviews': 'olist_order_reviews_dataset.csv',\n",
        "    'products': 'olist_products_dataset.csv',\n",
        "    'customers': 'olist_customers_dataset.csv',\n",
        "    'geolocation': 'olist_geolocation_dataset.csv',\n",
        "    'sellers': 'olist_sellers_dataset.csv',\n",
        "    'product_category': 'product_category_name_translation.csv'\n",
        "}\n",
        "\n",
        "# Función para cargar los datos\n",
        "# Un diccionario de DataFrames es una estructura de datos que combina dos elementos fundamentales de Python:\n",
        "# Diccionarios: Estructuras de pares clave-valor ({clave: valor})\n",
        "# DataFrames: Estructuras tabulares bidimensionales de la biblioteca Pandas\n",
        "# ¿Qué es exactamente? Es un diccionario donde:\n",
        "# 1. Las claves son identificadores (generalmente strings)\n",
        "# 2. Los valores son objetos DataFrame de Pandas\n",
        "def cargar_datos(archivos, data_path):\n",
        "    \"\"\"Carga todos los archivos CSV en un diccionario de DataFrames\"\"\"\n",
        "    datasets = {}\n",
        "\n",
        "    for nombre, archivo in archivos.items():\n",
        "        try:\n",
        "            ruta_completa = data_path + archivo\n",
        "            datasets[nombre] = pd.read_csv(ruta_completa)\n",
        "            print(f\"OK! {nombre}: {datasets[nombre].shape[0]:,} filas, {datasets[nombre].shape[1]} columnas\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"):- Error: No encontré el archivo {archivo}\")\n",
        "        except Exception as e:\n",
        "            print(f\"):- Error cargando el archivo {archivo}: {str(e)}\")\n",
        "\n",
        "    return datasets\n",
        "\n",
        "# Cargar todos los datasets desde los CSV\n",
        "print(\":-0 Cargando datasets...\")\n",
        "print(\"=\" * 50)\n",
        "data = cargar_datos(archivos, data_path)\n",
        "print(\"=\" * 50)\n",
        "print(f\";-) Total de datasets cargados: {len(data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 3: Limpieza y Preparación de los datos"
      ],
      "metadata": {
        "id": "vfussUBM2DQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Voy a limpiar los datos de los datasets (CSV)\n",
        "# Función de alumbrado barrido y limpieza\n",
        "def limpiar_datos(datasets):\n",
        "    \"\"\"Aplica limpieza de datos según especificaciones\"\"\"\n",
        "    print(\"LIMPIANDO LOS DATOS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    datasets_limpios = datasets.copy()\n",
        "\n",
        "    for nombre, df in datasets_limpios.items():\n",
        "        print(f\"\\n Limpiando a {nombre}...\")\n",
        "\n",
        "        # Identificar columnas con valores perdidos\n",
        "        columnas_faltantes = df.isnull().sum()\n",
        "        if columnas_faltantes.sum() > 0:\n",
        "            print(f\"   Encontré que hay valores perdidos:\")\n",
        "            for col, count in columnas_faltantes[columnas_faltantes > 0].items():\n",
        "                print(f\"      • {col}: {count:,} ({count/len(df)*100:.1f}%)\")\n",
        "\n",
        "                # Rellenar los perdidos según el tipo de dato. Si es número real\n",
        "                # le inserto la media aritmética, si es entero le inserto la moda\n",
        "                if df[col].dtype in ['float64', 'int64']:\n",
        "                    promedio = df[col].mean()\n",
        "                    df[col].fillna(promedio, inplace=True)\n",
        "                    print(f\"        → Rellenado con promedio: {promedio:.2f}\")\n",
        "                else:\n",
        "                    moda = df[col].mode().iloc[0] if len(df[col].mode()) > 0 else 'Sin información'\n",
        "                    df[col].fillna(moda, inplace=True)\n",
        "                    print(f\"        → Rellenado con moda: {moda}\")\n",
        "        else:\n",
        "            print(f\"   OK. No hubo valores perdidos\")\n",
        "\n",
        "        # Convertir columnas de fecha\n",
        "        columnas_fecha = [col for col in df.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
        "        if columnas_fecha:\n",
        "            print(f\"   Convirtiendo fechas: {columnas_fecha}\")\n",
        "            for col in columnas_fecha:\n",
        "                try:\n",
        "                    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "                    print(f\"       {col}: convertido a timestamp\")\n",
        "                except:\n",
        "                    print(f\"       {col}: error en conversión\")\n",
        "\n",
        "    print(\"\\n OK! LIMPIEZA COMPLETADA\")\n",
        "    return datasets_limpios\n",
        "\n",
        "# Aplicar limpieza\n",
        "data_clean = limpiar_datos(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07bSCSKn2UjK",
        "outputId": "5427965d-3c35-4717-d2e6-fdbd0f7c15f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIMPIANDO LOS DATOS\n",
            "==================================================\n",
            "\n",
            " Limpiando a orders...\n",
            "   Encontré que hay valores perdidos:\n",
            "      • order_approved_at: 160 (0.2%)\n",
            "        → Rellenado con moda: 2018-02-27 04:31:10\n",
            "      • order_delivered_carrier_date: 1,783 (1.8%)\n",
            "        → Rellenado con moda: 2018-05-09 15:48:00\n",
            "      • order_delivered_customer_date: 2,965 (3.0%)\n",
            "        → Rellenado con moda: 2016-10-27 17:32:07\n",
            "   Convirtiendo fechas: ['order_purchase_timestamp', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
            "       order_purchase_timestamp: convertido a timestamp\n",
            "       order_delivered_carrier_date: convertido a timestamp\n",
            "       order_delivered_customer_date: convertido a timestamp\n",
            "       order_estimated_delivery_date: convertido a timestamp\n",
            "\n",
            " Limpiando a order_items...\n",
            "   OK. No hubo valores perdidos\n",
            "   Convirtiendo fechas: ['shipping_limit_date']\n",
            "       shipping_limit_date: convertido a timestamp\n",
            "\n",
            " Limpiando a order_payments...\n",
            "   OK. No hubo valores perdidos\n",
            "\n",
            " Limpiando a order_reviews...\n",
            "   Encontré que hay valores perdidos:\n",
            "      • review_comment_title: 87,656 (88.3%)\n",
            "        → Rellenado con moda: Recomendo\n",
            "      • review_comment_message: 58,247 (58.7%)\n",
            "        → Rellenado con moda: Muito bom\n",
            "   Convirtiendo fechas: ['review_creation_date', 'review_answer_timestamp']\n",
            "       review_creation_date: convertido a timestamp\n",
            "       review_answer_timestamp: convertido a timestamp\n",
            "\n",
            " Limpiando a products...\n",
            "   Encontré que hay valores perdidos:\n",
            "      • product_category_name: 610 (1.9%)\n",
            "        → Rellenado con moda: cama_mesa_banho\n",
            "      • product_name_lenght: 610 (1.9%)\n",
            "        → Rellenado con promedio: 48.48\n",
            "      • product_description_lenght: 610 (1.9%)\n",
            "        → Rellenado con promedio: 771.50\n",
            "      • product_photos_qty: 610 (1.9%)\n",
            "        → Rellenado con promedio: 2.19\n",
            "      • product_weight_g: 2 (0.0%)\n",
            "        → Rellenado con promedio: 2276.47\n",
            "      • product_length_cm: 2 (0.0%)\n",
            "        → Rellenado con promedio: 30.82\n",
            "      • product_height_cm: 2 (0.0%)\n",
            "        → Rellenado con promedio: 16.94\n",
            "      • product_width_cm: 2 (0.0%)\n",
            "        → Rellenado con promedio: 23.20\n",
            "\n",
            " Limpiando a customers...\n",
            "   OK. No hubo valores perdidos\n",
            "\n",
            " Limpiando a geolocation...\n",
            "   OK. No hubo valores perdidos\n",
            "\n",
            " Limpiando a sellers...\n",
            "   OK. No hubo valores perdidos\n",
            "\n",
            " Limpiando a product_category...\n",
            "   OK. No hubo valores perdidos\n",
            "\n",
            " OK! LIMPIEZA COMPLETADA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 4: Cear el Dataset Principal"
      ],
      "metadata": {
        "id": "g-FoXiZhoWh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Super función que une las tablas más importantes\n",
        "#\n",
        "# CUSTOMERS (99K) ←→ ORDERS (99K) ←→ ORDER_ITEMS (113K) ←→ PRODUCTS (33K)\n",
        "#                        ↓                    ↓\n",
        "#                  PAYMENTS (104K)      SELLERS (3K)\n",
        "#                        ↓\n",
        "#                   REVIEWS (99K)\n",
        "#\n",
        "# GEOLOCATION (1M) ←→ ZIP_CODES (customers/sellers)\n",
        "#\n",
        "def crear_dataset_principal(datasets):\n",
        "    \"\"\"Crear dataset principal uniendo las tablas más importantes\"\"\"\n",
        "    print(\"|:-o CREANDO DATASET PRINCIPAL\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Comenzar con orders como tabla base\n",
        "    df_principal = datasets['orders'].copy()\n",
        "    print(f\" Base - Orders: {len(df_principal):,} registros\")\n",
        "\n",
        "    # Unir con customers\n",
        "    if 'customers' in datasets:\n",
        "        df_principal = df_principal.merge(\n",
        "            datasets['customers'],\n",
        "            on='customer_id',\n",
        "            how='left'\n",
        "        )\n",
        "        print(f\"Ok -> Customers: {len(df_principal):,} registros\")\n",
        "\n",
        "    # Unir con order_items\n",
        "    if 'order_items' in datasets:\n",
        "        df_principal = df_principal.merge(\n",
        "            datasets['order_items'],\n",
        "            on='order_id',\n",
        "            how='left'\n",
        "        )\n",
        "        print(f\"Ok -> Order Items: {len(df_principal):,} registros\")\n",
        "\n",
        "    # Unir con products\n",
        "    if 'products' in datasets:\n",
        "        df_principal = df_principal.merge(\n",
        "            datasets['products'],\n",
        "            on='product_id',\n",
        "            how='left'\n",
        "        )\n",
        "        print(f\"Ok -> Products: {len(df_principal):,} registros\")\n",
        "\n",
        "    # Unir con sellers\n",
        "    if 'sellers' in datasets:\n",
        "        df_principal = df_principal.merge(\n",
        "            datasets['sellers'],\n",
        "            on='seller_id',\n",
        "            how='left'\n",
        "        )\n",
        "        print(f\"Ok -> Sellers: {len(df_principal):,} registros\")\n",
        "\n",
        "    # Agregar información de pagos\n",
        "    if 'order_payments' in datasets:\n",
        "        pagos_agregados = datasets['order_payments'].groupby('order_id').agg({\n",
        "            'payment_value': 'sum',\n",
        "            'payment_type': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'unknown',\n",
        "            'payment_installments': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        df_principal = df_principal.merge(\n",
        "            pagos_agregados,\n",
        "            on='order_id',\n",
        "            how='left'\n",
        "        )\n",
        "        print(f\"Ok -> Payments: {len(df_principal):,} registros\")\n",
        "\n",
        "    # Agregar información de reviews\n",
        "    if 'order_reviews' in datasets:\n",
        "        reviews_agregados = datasets['order_reviews'].groupby('order_id').agg({\n",
        "            'review_score': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        df_principal = df_principal.merge(\n",
        "            reviews_agregados,\n",
        "            on='order_id',\n",
        "            how='left'\n",
        "        )\n",
        "        print(f\"Ok + Reviews: {len(df_principal):,} registros\")\n",
        "\n",
        "    print(f\"\\n ;-) Dataset principal creado: {len(df_principal):,} registros, {len(df_principal.columns)} columnas\")\n",
        "\n",
        "    return df_principal\n",
        "\n",
        "# Crear dataset principal\n",
        "df_main = crear_dataset_principal(data_clean)\n",
        "\n",
        "# Mostrar información básica\n",
        "print(\"\\n INFORMACIÓN DEL DATASET PRINCIPAL:\")\n",
        "print(df_main.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPEcCnSMog0u",
        "outputId": "3435f9fd-74ae-4cb5-f2fe-301323165777"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|:-o CREANDO DATASET PRINCIPAL\n",
            "========================================\n",
            " Base - Orders: 99,441 registros\n",
            "Ok -> Customers: 99,441 registros\n",
            "Ok -> Order Items: 113,425 registros\n",
            "Ok -> Products: 113,425 registros\n",
            "Ok -> Sellers: 113,425 registros\n",
            "Ok -> Payments: 113,425 registros\n",
            "Ok + Reviews: 113,425 registros\n",
            "\n",
            " ;-) Dataset principal creado: 113,425 registros, 33 columnas\n",
            "\n",
            " INFORMACIÓN DEL DATASET PRINCIPAL:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 113425 entries, 0 to 113424\n",
            "Data columns (total 33 columns):\n",
            " #   Column                         Non-Null Count   Dtype         \n",
            "---  ------                         --------------   -----         \n",
            " 0   order_id                       113425 non-null  object        \n",
            " 1   customer_id                    113425 non-null  object        \n",
            " 2   order_status                   113425 non-null  object        \n",
            " 3   order_purchase_timestamp       113425 non-null  datetime64[ns]\n",
            " 4   order_approved_at              113425 non-null  object        \n",
            " 5   order_delivered_carrier_date   113425 non-null  datetime64[ns]\n",
            " 6   order_delivered_customer_date  113425 non-null  datetime64[ns]\n",
            " 7   order_estimated_delivery_date  113425 non-null  datetime64[ns]\n",
            " 8   customer_unique_id             113425 non-null  object        \n",
            " 9   customer_zip_code_prefix       113425 non-null  int64         \n",
            " 10  customer_city                  113425 non-null  object        \n",
            " 11  customer_state                 113425 non-null  object        \n",
            " 12  order_item_id                  112650 non-null  float64       \n",
            " 13  product_id                     112650 non-null  object        \n",
            " 14  seller_id                      112650 non-null  object        \n",
            " 15  shipping_limit_date            112650 non-null  datetime64[ns]\n",
            " 16  price                          112650 non-null  float64       \n",
            " 17  freight_value                  112650 non-null  float64       \n",
            " 18  product_category_name          112650 non-null  object        \n",
            " 19  product_name_lenght            112650 non-null  float64       \n",
            " 20  product_description_lenght     112650 non-null  float64       \n",
            " 21  product_photos_qty             112650 non-null  float64       \n",
            " 22  product_weight_g               112650 non-null  float64       \n",
            " 23  product_length_cm              112650 non-null  float64       \n",
            " 24  product_height_cm              112650 non-null  float64       \n",
            " 25  product_width_cm               112650 non-null  float64       \n",
            " 26  seller_zip_code_prefix         112650 non-null  float64       \n",
            " 27  seller_city                    112650 non-null  object        \n",
            " 28  seller_state                   112650 non-null  object        \n",
            " 29  payment_value                  113422 non-null  float64       \n",
            " 30  payment_type                   113422 non-null  object        \n",
            " 31  payment_installments           113422 non-null  float64       \n",
            " 32  review_score                   112464 non-null  float64       \n",
            "dtypes: datetime64[ns](5), float64(14), int64(1), object(13)\n",
            "memory usage: 28.6+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **>>>ANÁLISIS PARA RESPONDER LAS PREGUNTAS<<<**"
      ],
      "metadata": {
        "id": "Cvl-WNFVxS8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "`Pregunta 3: ¿cuáles son los productos más pedidos por estado?`"
      ],
      "metadata": {
        "id": "y4b5dGBzrRgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para investigar cómo se dan los pedidos (órdenes) de compra según el estado\n",
        "def analizar_distribución_estados(df):\n",
        "    \"\"\"Analizamos la distribución de órdenes por estado\"\"\"\n",
        "    print(\"* ANÁLISIS: Distribución de Órdenes por Estado\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    if 'customer_state' in df.columns:\n",
        "        distribucion_estados = df.groupby('customer_state').agg({\n",
        "            'order_id': 'nunique',\n",
        "            'customer_id': 'nunique',\n",
        "            'payment_value': 'sum'\n",
        "        }).round(2)\n",
        "\n",
        "        distribucion_estados.columns = ['Total_Ordenes', 'Clientes_Unicos', 'Valor_Total']\n",
        "        distribucion_estados['Porcentaje_Ordenes'] = (\n",
        "            distribucion_estados['Total_Ordenes'] / distribucion_estados['Total_Ordenes'].sum() * 100\n",
        "        ).round(2)\n",
        "\n",
        "        distribucion_estados = distribucion_estados.sort_values('Total_Ordenes', ascending=False)\n",
        "        # muestro ranking de los 10 estados top\n",
        "        print(\"* TOP 10 ESTADOS POR CANTIDAD DE ÓRDENES:\")\n",
        "        print(distribucion_estados.head(10))\n",
        "\n",
        "        print(f\"\\n|<- INFORMACIÓN CLAVE:\")\n",
        "        print(f\"• El estado líder es: {distribucion_estados.index[0]} ({distribucion_estados.iloc[0]['Porcentaje_Ordenes']:.1f}% del total)\")\n",
        "        print(f\"• Los 3 estados Top concentran: {distribucion_estados.head(3)['Porcentaje_Ordenes'].sum():.1f}% de las órdenes\")\n",
        "        print(f\"• Total de estados activos: {len(distribucion_estados)}\")\n",
        "\n",
        "        return distribucion_estados\n",
        "    else:\n",
        "        print(\"):-() Columna 'customer_state' no encontrada\")\n",
        "        return None\n",
        "\n",
        "# Ejecutar análisis\n",
        "resultado_estados = analizar_distribución_estados(df_main)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JyJggtFr8oP",
        "outputId": "5837b954-2297-4f3d-bde9-538e443d181f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* ANÁLISIS: Distribución de Órdenes por Estado\n",
            "==================================================\n",
            "* TOP 10 ESTADOS POR CANTIDAD DE ÓRDENES:\n",
            "                Total_Ordenes  Clientes_Unicos  Valor_Total  \\\n",
            "customer_state                                                \n",
            "SP                      41746            41746   7673188.55   \n",
            "RJ                      12852            12852   2783724.26   \n",
            "MG                      11635            11635   2341861.47   \n",
            "RS                       5466             5466   1152019.17   \n",
            "PR                       5045             5045   1074614.19   \n",
            "SC                       3637             3637    799135.92   \n",
            "BA                       3380             3380    802416.72   \n",
            "DF                       2140             2140    434512.55   \n",
            "ES                       2033             2033    406946.26   \n",
            "GO                       2020             2020    516182.51   \n",
            "\n",
            "                Porcentaje_Ordenes  \n",
            "customer_state                      \n",
            "SP                           41.98  \n",
            "RJ                           12.92  \n",
            "MG                           11.70  \n",
            "RS                            5.50  \n",
            "PR                            5.07  \n",
            "SC                            3.66  \n",
            "BA                            3.40  \n",
            "DF                            2.15  \n",
            "ES                            2.04  \n",
            "GO                            2.03  \n",
            "\n",
            "|<- INFORMACIÓN CLAVE:\n",
            "• El estado líder es: SP (42.0% del total)\n",
            "• Los 3 estados Top concentran: 66.6% de las órdenes\n",
            "• Total de estados activos: 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "`Pregunta 5: ¿cuáles son los métodos de pago más utilizados?`\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r0peOIB5uOvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para investigar cuáles son los métodos de pago más usuales\n",
        "def analizar_métodos_pago():\n",
        "    \"\"\"Analizamos los métodos de pago más utilizados\"\"\"\n",
        "    print(\"* ANÁLISIS: Métodos de Pago Más Utilizados\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    if 'order_payments' in data_clean:\n",
        "        df_pagos = data_clean['order_payments']\n",
        "\n",
        "        metodos_pago = df_pagos.groupby('payment_type').agg({\n",
        "            'order_id': 'count',\n",
        "            'payment_value': ['sum', 'mean'],\n",
        "            'payment_installments': 'mean'\n",
        "        }).round(2)\n",
        "\n",
        "        metodos_pago.columns = ['Num_Transacciones', 'Valor_Total', 'Valor_Promedio', 'Cuotas_Promedio']\n",
        "        metodos_pago['Porcentaje_Uso'] = (\n",
        "            metodos_pago['Num_Transacciones'] / metodos_pago['Num_Transacciones'].sum() * 100\n",
        "        ).round(2)\n",
        "\n",
        "        metodos_pago = metodos_pago.sort_values('Num_Transacciones', ascending=False)\n",
        "\n",
        "        print(\" MÉTODOS DE PAGO ORDENADOS POR USO:\")\n",
        "        print(metodos_pago)\n",
        "\n",
        "        print(f\"\\n INFORMACIÓN CLAVE:\")\n",
        "        print(f\"• Método más usado: {metodos_pago.index[0]} ({metodos_pago.iloc[0]['Porcentaje_Uso']:.1f}% de transacciones)\")\n",
        "        print(f\"• Valor promedio más alto: {metodos_pago['Valor_Promedio'].idxmax()} (R$ {metodos_pago['Valor_Promedio'].max():.2f})\")\n",
        "\n",
        "        return metodos_pago\n",
        "    else:\n",
        "        print(\")8-( Dataset de pagos no encontrado\")\n",
        "        return None\n",
        "\n",
        "# Ejecutar análisis\n",
        "resultado_pagos = analizar_métodos_pago()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QZk4DoKujqb",
        "outputId": "aabdf242-ecb3-4294-c62d-88ee89cb3efd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* ANÁLISIS: Métodos de Pago Más Utilizados\n",
            "==================================================\n",
            " MÉTODOS DE PAGO ORDENADOS POR USO:\n",
            "              Num_Transacciones  Valor_Total  Valor_Promedio  Cuotas_Promedio  \\\n",
            "payment_type                                                                    \n",
            "credit_card               76795  12542084.19          163.32             3.51   \n",
            "boleto                    19784   2869361.27          145.03             1.00   \n",
            "voucher                    5775    379436.87           65.70             1.00   \n",
            "debit_card                 1529    217989.79          142.57             1.00   \n",
            "not_defined                   3         0.00            0.00             1.00   \n",
            "\n",
            "              Porcentaje_Uso  \n",
            "payment_type                  \n",
            "credit_card            73.92  \n",
            "boleto                 19.04  \n",
            "voucher                 5.56  \n",
            "debit_card              1.47  \n",
            "not_defined             0.00  \n",
            "\n",
            " INFORMACIÓN CLAVE:\n",
            "• Método más usado: credit_card (73.9% de transacciones)\n",
            "• Valor promedio más alto: credit_card (R$ 163.32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Pregunta 3:\n"
      ],
      "metadata": {
        "id": "TQ59yy2iwNUn"
      }
    }
  ]
}